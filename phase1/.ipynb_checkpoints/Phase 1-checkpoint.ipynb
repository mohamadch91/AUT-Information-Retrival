{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19287de",
   "metadata": {},
   "source": [
    "# Information retrival project phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd227b",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7a7b7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import *\n",
    "from __future__ import unicode_literals\n",
    "# from parsivar import *\n",
    "import json\n",
    "import string\n",
    "from hazm import stopwords_list\n",
    "from copy import copy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c93a7",
   "metadata": {},
   "source": [
    "## Reading Json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4059df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"IR_data_news_12k.json\")\n",
    "data=json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3dbd23",
   "metadata": {},
   "source": [
    "## create empty arrays to store contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2cded74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_content=[]\n",
    "data_url=[]\n",
    "data_title=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57310754",
   "metadata": {},
   "source": [
    "## store content in arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580d6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    index=str(i)\n",
    "    data_content.append(data[\"\"+index][\"content\"])\n",
    "    data_url.append(data[\"\"+index][\"url\"])\n",
    "    data_title.append(data[\"\"+index][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da73b1aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#comment after complete\n",
    "data_content=data_content[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95133196",
   "metadata": {},
   "source": [
    "## define new array for tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8eea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tokens=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c7107",
   "metadata": {},
   "source": [
    "# preproccesing start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c1ea4",
   "metadata": {},
   "source": [
    "## normalize contents\n",
    "tokenize and stemmer and lematize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266fb230",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "stemmer = Stemmer()\n",
    "stop_words=set(stopwords_list())\n",
    "stop_words.add('\\u200cو')\n",
    "stop_words.add('\\u200cو')\n",
    "stop_words.add('و\\u200c')\n",
    "lemmatizer = Lemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1254b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b790a9cd",
   "metadata": {},
   "source": [
    "## define punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3709c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations=string.punctuation \n",
    "temp_list=set()\n",
    "for i in punctuations:\n",
    "    temp_list.add(i)\n",
    "temp_list.add('،')\n",
    "temp_list.add('.')\n",
    "temp_list.add(':')\n",
    "punctuations=temp_list.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa94dd",
   "metadata": {},
   "source": [
    "### loop over te content and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75af7c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['به', 'گزارش', 'خبرنگار', 'ورزشی', 'خبرگزاری', 'فارس', '،', 'تیم', 'فوتبال', 'استقلال', 'در', 'آخرین', 'مسابقه', 'از', 'هفته', 'نوزدهم', 'لیگ', 'برتر', 'از', 'ساعت', '۱۹', 'در', 'ورزشگاه', 'آزادی', 'به', 'مصاف', 'تیم', 'فجرشهید', 'سپاسی', 'رفت', 'که', 'مسابقه', 'با', 'نتیجه', 'یک', 'بر', 'صفر', 'به', 'سود', 'استقلال', 'به', 'پایان', 'رسید', '.', 'تیم', 'فوتبال', 'استقلال', 'ششمین', 'برد', 'متوالی', 'فصل', 'خود', 'را', 'به', 'دست', 'آورد', 'تا', 'با', '۴۷', 'امتیاز', 'فرار', 'بزرگی', 'را', 'به', 'سوی', 'قهرمانی', 'لیگ', 'برتر', 'بیست', 'و', 'یکم', 'آغاز', 'کند', '.', 'آبی', 'پوشان', 'تهرانی', 'اختلاف', 'امتیازی', 'خود', 'را', 'با', 'پرسپولیس', 'به', '۵', 'رساندند', '.', 'آن', 'هم', 'در', 'شرایطی', 'که', 'سیاوش', 'یزدانی', 'و', 'حسین', 'مرادمند', 'دو', 'مدافع', 'اصلی', 'خود', 'را', 'به', 'دلیل', 'خدمت', 'سربازی', 'در', 'اختیار', 'نداشت', '.', 'البته', 'این', 'دو', 'بازیکن', 'از', 'روی', 'سکو', 'نظاره\\u200cگر', 'مسابقه', 'برد', 'تیم', 'شان', 'بودند', '.', 'پرسپولیس', 'امشب', 'مقابل', 'گل', 'گهرسیرجان', 'متوقف', 'شد', '.', 'فجرسپاسی', 'هم', 'با', '۱۴', 'امتیاز', 'در', 'رده', 'چهاردهم', 'جدول', 'و', 'خطر', 'سقوط', 'به', 'لیگ', 'یک', 'قرار', 'دارد', '.', 'این', 'تیم', 'با', '۷', 'گل', 'زده', 'ضعیف\\u200cترین', 'خط', 'حمله', 'لیگ', 'را', 'در', 'اختیار', 'دارد', 'و', 'حتی', 'از', 'پدیده', 'مشهد', 'قعرنشین', 'لیگ', 'هم', 'یک', 'گل', 'کمتر', 'زده_است', '.', 'آخرین', 'برد', 'فجر', 'در', 'هفته', 'پنجم', 'مقابل', 'پیکان', 'تهران', 'بود', '.', 'داور', ':', 'رضا', 'عادل', 'کمک', 'داوران', ':', 'علیرضا', 'ایلدروم', '–', 'حسن', 'انتظاری', 'کارت', 'زرد', ':', 'بهزاد', 'غلامپور', '(', 'مربی', ')', '،', 'روزبه', 'چشمی', '،', 'فرزاد', 'مجیدی', '(', 'مربی', ')', '(', 'استقلال', ')', 'دانیال', 'کردستانی', '،', 'رضا', 'علیاری', '،', 'فرزان', 'دانا', '(', 'فجرشهید', 'سپاسی', ')', 'کارت', 'قرمز', ':', 'گل', ':', 'جعفر', 'سلمانی', '(', 'دقیقه', '۵۴', ')', 'برای', 'استقلال', 'ترکیب', 'استقلال', ':', 'سید', 'حسین', 'حسینی', '،', 'روزبه', 'چشمی', '،', 'زبیر', 'نیک\\u200cنفس', '،', 'محمد', 'دانشگر', '،', 'مهدی', 'مهدی\\u200cپور', '،', 'جعفر', 'سلمانی', '(', 'از', 'دقیقه', '۱+', '۹۰', 'عارف', 'غلامی', ')', '،', 'صالح', 'حردانی', '،', 'امیرحسین', 'حسین\\u200cزاده', '(', 'از', 'دقیقه', '۸۶', 'سعید', 'مهری', ')', '،', 'کوین', 'یامگا', '،', 'عزیزبک', 'آمانوف', '(', 'از', 'دقیقه', '۶۰', 'امیرعلی', 'صادقی', ')', 'و', 'رودی', 'ژستد', '(', 'از', 'دقیقه', '۸۶', 'ارسلان', 'مطهری', ')', '.', 'سرمربی', ':', 'فرهاد', 'مجیدی', 'ترکیب', 'فجرشهید', 'سپاسی', ':', 'ایمان', 'صادقی', '،', 'محمد', 'قنبری', '،', 'علی', 'مولایی', '،', 'رضا', 'علیاری', '،', 'حمید', 'نعمتی', '(', 'از', 'دقیقه', '۸۰', 'شهرام', 'گودرزی', ')', '،', 'احمدرضا', 'زنده', 'روح', '(', 'از', 'دقیقه', '۸۰', 'علی', 'نبی', 'زاده', ')', '،', 'دانیال', 'کردستانی', '(', 'از', 'دقیقه', '۵۹', 'محمد', 'عرفان', 'معصومی', ')', '،', 'یوسف', 'وکیا', '،', 'اتابک', 'زارعی', '(', 'از', 'دقیقه', '۴۶', 'محمدرضا', 'خدری', ')', '،', 'فرزان', 'دانا', '،', 'محمد', 'کاظمی', '(', 'از', 'دقیقه', '۵۸', 'حسین', 'مهربان', ')', 'سرمربی', ':', 'علی', 'اصغر', 'کلانتری', 'دقیقه', '۲:', 'پاس', 'خوب', 'حسین', 'زاده', 'در', 'محوطه', 'جریمه', 'به', 'یامگا', 'یک', 'فرصت', 'گلزنی', 'عالی', 'برای', 'استقلال', 'خلق', 'کرد', 'اما', 'شوت', 'مهاجم', 'آبی', 'پوشان', 'را', 'درواز\\u200cه\\u200cبان', 'فجر', 'دفع', 'کرد', 'و', 'توپ', 'به', 'کرنر', 'رفت', 'که', 'این', 'کرنر', 'هم', 'حاصلی', 'برای', 'استقلال', 'نداشت', '.', 'دقیقه', '۷:', 'شوت', 'حسین\\u200cزاده', 'از', 'پشت', 'محوطه', 'جریمه', 'با', 'اختلاف', 'کمی', 'از', 'کنار', 'دروازه', 'فجر', 'سپاسی', 'به', 'بیرون', 'رفت', '.', 'دقیقه', '۱۷:', 'ارسال', 'صالح', 'حردانی', 'در', 'محوطه', 'جریمه', 'به', 'ژستد', 'رسید', 'و', 'ضربه', 'سر', 'او', 'با', 'اختلاف', 'کمی', 'از', 'بالای', 'دروازه', 'فجر', 'به', 'بیرون', 'رفت', '.', 'دقیقه', '۲۱:', 'شوت', 'از', 'راه', 'دور', 'مهدی', 'پور', 'را', 'دروازه\\u200cبان', 'فجر', 'سپاسی', 'ایمان', 'صادقی', 'دفع', 'کرد', '.', 'دقیقه', '۲۳:', 'ضربه', 'کاشته', 'فجر', 'سپاسی', 'را', 'مدافعان', 'استقلال', 'دفع', 'کردند', 'و', 'ضربه', 'کرنر', 'هم', 'حاصلی', 'برای', 'این', 'تیم', 'نداشت', '.', 'دقیقه', '۲۵:', 'ضربه', 'سر', 'مهاجم', 'استقلال', 'با', 'اختلاف', 'از', 'بالای', 'دروازه', 'فجر', 'به', 'بیرون', 'رفت', '.', 'دقیقه', '۲۸:', 'شوت', 'حردانی', 'با', 'واکنش', 'خوب', 'ایمان', 'صادقی', 'دروازه\\u200cبان', 'تیم', 'فجر', 'راهی', 'کرنر', 'شد', 'و', 'مهدی', 'پور', 'ضربه', 'کرنر', 'را', 'زد', 'که', 'مدافعان', 'فجر', 'توپ', 'را', 'دفع', 'کردند', '.', 'دقیقه', '۳۱:', 'شوت', 'امانوف', 'از', 'داخل', 'محوطه', 'جریمه', 'را', 'بازهم', 'دروازه\\u200cبان', 'فجر', 'راهی', 'کرنر', 'کرد', '.', 'ضربه', 'کرنر', 'این', 'مرتبه', 'به', 'بعد', 'از', 'یک', 'رفت', 'و', 'برگشت', 'به', 'سلمانی', 'رسید', 'و', 'شوت', 'او', 'با', 'اختلاف', 'از', 'بالای', 'دروازه', 'فجر', 'به', 'بیرون', 'رفت', '.', 'دقیقه', '۳۶:', 'زنده', 'روح', 'ضربه', 'کاشته', 'فجر', 'را', 'روی', 'دروازه', 'استقلال', 'فرستاد', 'که', 'مدافعان', 'توپ', 'را', 'به', 'کرنر', 'فرستادند', 'که', 'ضربه', 'کرنر', 'را', 'حسینی', 'دروازه\\u200cبان', 'استقلال', 'با', 'مشت', 'توپ', 'را', 'دور', 'کرد', '.', 'نیمه', 'دوم', 'دقیقه', '۵۰:', 'شوت', 'از', 'راه', 'دور', 'نیک', 'نفس', 'را', 'بازهم', 'صادقی', 'دروازه\\u200cبان', 'فجر', 'با', 'یک', 'شیرجه', 'راهی', 'کرنر', 'کرد', '.', 'این', 'کرنر', 'حاصلی', 'برای', 'آبی', 'پوشان', 'نداشت', 'و', 'ضربه', 'سر', 'دانشگر', 'از', 'بالای', 'دروازه', 'فجر', 'به', 'بیرون', 'رفت', '.', 'دقیقه', '۵۴:', 'ضربه', 'کاشته', 'استقلال', 'را', 'مهدی', 'پور', 'روی', 'دروازه', 'فجر', 'فرستاد', 'که', 'مدافعان', 'توپ', 'را', 'به', 'کرنر', 'فرستادند', '.', 'این', 'کرنر', 'را', 'هم', 'مهدی', 'پور', 'زد', 'و', 'در', 'نهایت', 'توپ', 'به', 'جعفر', 'سلمانی', 'رسید', 'و', 'او', 'هم', 'با', 'یک', 'شوت', 'زمینی', 'گل', 'اول', 'استقلال', 'را', 'به', 'ثمر', 'رساند', '.', 'دقیقه', '۶۹:', 'صادقی', 'ضربه', 'کرنر', 'استقلال', 'را', 'زد', 'اما', 'چشمی', 'در', 'محوطه', 'جریمه', 'روی', 'صادقی', 'دروازه', 'بان', 'فجر', 'مرتکب', 'خطا', 'شده_است', '.', 'دقیقه', '۷۱:', 'ضربه', 'کرنر', 'فجر', 'را', 'مدافعان', 'استقلال', 'دور', 'کردند', 'که', 'توپ', 'برگشتی', 'را', 'زنده', 'روح', 'شوت', 'کرد', 'اما', 'با', 'اختلاف', 'زیادی', 'از', 'کنار', 'دروازه', 'استقلال', 'به', 'بیرون', 'رفت', '.', 'دقیقه', '۷۵:', 'حسین', 'مهربان', 'در', 'محوطه', 'جریمه', 'استقلال', 'سرنگون', 'شد', 'اما', 'داور', 'اعتقادی', 'به', 'پنالتی', 'نداشت', 'با', 'این', 'حال', 'بازیکنان', 'فجر', 'به', 'تصمیم', 'داور', 'معترض', 'شدند', '.', 'دقیقه', '۷۸:', 'ضربه', 'یامگا', 'را', 'دروازه\\u200cبان', 'فجر', 'مهار', 'کرد', '.', 'دقیقه', '۸۳:', 'شوت', 'نیک', 'نفس', 'را', 'دروازه', 'بان', 'فجر', 'در', 'حالیکه', 'بیرون', 'از', 'دروازه', 'هم', 'بود', 'با', 'یک', 'شیرجه', 'راهی', 'کرنر', 'کرد', '.', 'ضربه', 'کرنر', 'را', 'هم', 'صادقی', 'مهار', 'کرد', '.', 'دقیقه', '۸۷:', 'شوت', 'علیاری', 'با', 'اختلاف', 'زیادی', 'از', 'بالای', 'دروازه', 'استقلال', 'به', 'بیرون', 'رفت', '.', 'دقیقه', '۹۰:', 'شوت', 'سعید', 'مهری', 'را', 'صادقی', 'با', 'یک', 'واکنش', 'خوب', 'راهی', 'کرنر', 'کرد', 'و', 'این', 'ضربه', 'کرنر', 'حاصلی', 'برای', 'این', 'تیم', 'نداشت', '.', 'دقیقه', '۱+', '۹۰:', 'مدافع', 'فجر', 'یامگا', 'را', 'با', 'دست', 'درون', 'محوطه', 'جریمه', 'متوقف', 'کرد', 'اما', 'داور', 'اعتقادی', 'به', 'پنالتی', 'نداشت', '.', 'دقیقه', '۲+', '۹۰:', 'فجر', 'بعد', 'از', 'اعلام', 'خطا', 'روی', 'مدافع', 'استقلال', 'گلزنی', 'کرد', 'که', 'این', 'گل', 'کاملا', 'مردود', 'بود', '.', 'دقیقه', '۳+', '۹۰:', 'پرتاب', 'بلند', 'وت', 'یک', 'فرصت', 'گلزنی', 'برای', 'فجر', 'مهیا', 'ساخت', 'که', 'مدافعان', 'توپ', 'را', 'دفع', 'کردند', '.', 'دقیقه', '۵+', '۹۰', 'شوت', 'از', 'راه', 'دور', 'بازیکن', 'استقلال', 'را', 'دروازه', 'بان', 'فجر', 'به', 'کمک', 'تیرک', 'دروازه', 'دفع', 'کرد', '.', 'انتهای', 'پیام/']\n"
     ]
    }
   ],
   "source": [
    "for j in range (len(data_content)):\n",
    "    data_content[j]=normalizer.normalize(data_content[j])\n",
    "    new_contents=word_tokenize(data_content[j])\n",
    "    temp_contents=copy(new_contents)\n",
    "    if(j==1454):\n",
    "        print(temp_contents)\n",
    "    for k in range(len(temp_contents)):\n",
    "        if(temp_contents[k] in stop_words):\n",
    "            new_contents.remove(temp_contents[k])    \n",
    "        if(temp_contents[k] in punctuations):\n",
    "            new_contents.remove(temp_contents[k])\n",
    "    for k in range(len(new_contents)):\n",
    "        new_contents[k]=lemmatizer.lemmatize(new_contents[k])\n",
    "#         new_contents[k]=stemmer.stem(new_contents[k])\n",
    "\n",
    "    data_tokens.append(new_contents)            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb370f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f013195f",
   "metadata": {},
   "source": [
    "### indexing words \n",
    "making words indexing in contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6dfdf3",
   "metadata": {},
   "source": [
    "empty set for tokens index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0981076",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_token=dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338e7cd",
   "metadata": {},
   "source": [
    "## iterate over content and tokens \n",
    "find tokens index in each content and <br>\n",
    "find tokens count in each content<br>\n",
    "calculate tokens number in contents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a203436a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(data_tokens)):\n",
    "    for j in range(len(data_tokens[i])):\n",
    "        if(data_tokens[i][j] in final_token):\n",
    "            temp_string=final_token[data_tokens[i][j]]\n",
    "            last_content=temp_string.split(\"|\")\n",
    "            no=int(last_content[len(last_content)-1].split(\":\")[0].split(\"c\")[1])\n",
    "            if(no==i):\n",
    "                count=last_content[len(last_content)-1].split(\":\")\n",
    "                temp_count=int(count[len(count)-1].split(\"_\")[1])\n",
    "                temp_count+=1\n",
    "                new_string=\"\"\n",
    "                for s in range(len(last_content)-1):\n",
    "                    new_string+=last_content[s]+\"|\"\n",
    "#                 print(last_content[len(last_content)-1])\n",
    "                last_item=last_content[len(last_content)-1].split(\"_\")[0]+\",\"+str(j)+\"_\"+str(temp_count)+\"_\"\n",
    "                new_string+=last_item\n",
    "                final_token[data_tokens[i][j]]=new_string\n",
    "            else: \n",
    "                final_token[data_tokens[i][j]]+=\"|\"+\"c\"+str(i)+\":\"+str(j)+\"_1_\"\n",
    "        else:\n",
    "            final_token[data_tokens[i][j]]=\"|\"+\"c\"+str(i)+\":\"+str(j)+\"_1_\"\n",
    "#     print(i)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a63da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4b981e7",
   "metadata": {},
   "source": [
    "# User input Query\n",
    "get input from user to proccess query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c827a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please enter your input : \"تحریم هسته‌ای\"\n"
     ]
    }
   ],
   "source": [
    "query=input(\"please enter your input : \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dad3187",
   "metadata": {},
   "source": [
    "##### procces input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab6c7f",
   "metadata": {},
   "source": [
    "###### define list for searched wirds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ffda6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d98ec",
   "metadata": {},
   "source": [
    "#### define string for handle double quete (\" \")\n",
    "<br>\n",
    "define boolean for handle !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "78314a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.split(\" \")\n",
    "temp_string=\"\"\n",
    "forbidden=False\n",
    "query_tokens=set()\n",
    "forbiddens=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da6dd038",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in query.split(\" \"):\n",
    "    if(word==''):\n",
    "        continue\n",
    "    if(word[0]=='\"'):\n",
    "        temp_string+=word[1:]+\" \"\n",
    "        continue\n",
    "    if(temp_string!=\"\"):\n",
    "        if(word[len(word)-1]=='\"'):\n",
    "            temp_string+=word[:len(word)-1]\n",
    "            query_tokens.add(temp_string)\n",
    "            temp_string=\"\"\n",
    "        else:\n",
    "            temp_string+=word+\" \"\n",
    "        continue\n",
    "    if(word==\"!\"):\n",
    "        forbidden=True\n",
    "        continue\n",
    "    if(forbidden):\n",
    "        forbiddens.add(word)\n",
    "        forbidden=False\n",
    "        continue\n",
    "    query_tokens.add(word)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ba325",
   "metadata": {},
   "source": [
    "### finding query terms in tokens\n",
    "search in dic <br>\n",
    "and get token indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "410b19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dic=[]\n",
    "forbidden_dic=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa0553cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in query_tokens:\n",
    "        if(len(word.split(\" \"))==1):\n",
    "            if(word in final_token and word not in stop_words):\n",
    "                query_dic.append(final_token[word])\n",
    "        else:\n",
    "            qute=[]\n",
    "            words=word.split(\" \")\n",
    "            for x in words:\n",
    "                if(x in final_token and x not in stop_words):\n",
    "                    qute.append(final_token[x])      \n",
    "            query_dic.append(qute)  \n",
    "for k in forbiddens:\n",
    "    if(k in final_token):\n",
    "        forbidden_dic.append(final_token[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91af182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4fb3344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'تحریم هسته\\u200cای'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3307ca9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_dic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9147a423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9ae8adb",
   "metadata": {},
   "source": [
    "#### searching docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8d8f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c1549:97,119_2_']\n"
     ]
    }
   ],
   "source": [
    "docs_point={}\n",
    "for address in query_dic:\n",
    "        if(type(address) is list):\n",
    "            intersection=[]\n",
    "            flag=False\n",
    "            for x in address:\n",
    "                if(len(intersection)==0):\n",
    "                    intersection.append(x)\n",
    "                else:\n",
    "                    intersection_dic={}\n",
    "                    x_dic={}\n",
    "                    answer={}\n",
    "                    inter_doc=intersection[0].split(\"|\")\n",
    "                    inter_doc=inter_doc[1:]\n",
    "                    \n",
    "                    for j in inter_doc:\n",
    "                        docno=j.split(\":\")[0]\n",
    "                        indexes=j.split(\":\")[1]\n",
    "                        intersection_dic[docno]=indexes\n",
    "                    x_doc=x.split(\"|\")\n",
    "                    x_doc=x_doc[1:]\n",
    "                    print(x_doc)\n",
    "                    for j in x_doc:\n",
    "                        x_docno=j.split(\":\")[0]\n",
    "                        x_index=j.split(\":\")[1]\n",
    "                        x_dic[x_docno]=x_index\n",
    "                    for key in intersection_dic.keys():\n",
    "                        if(key in x_dic):\n",
    "                            inter_index=intersection_dic[key].split(\"_\")[0].split(\",\")\n",
    "                            x_index=x_dic[key].split(\"_\")[0].split(\",\")\n",
    "                            for s in inter_index:\n",
    "                                for m in x_index:\n",
    "                                    index_no_inter=int(s)\n",
    "                                    index_no_x=int(m)\n",
    "                                    dif=index_no_x-index_no_inter\n",
    "                                    if(dif==1):\n",
    "                                        if(key in answer):\n",
    "                                            ans_index=answer[key]\n",
    "                                            ans_count=int(ans_index.split(\"_\")[1])\n",
    "                                            ans_indexes=ans_index.split(\"_\")[0]\n",
    "                                            ans_indexes+=\",\"+str(m)\n",
    "                                            ans_count+=1\n",
    "                                            temp_ans=ans_indexes+\"_\"+str(ans_count)+\"_\"\n",
    "                                            answer[key]=temp_ans\n",
    "                                        else:\n",
    "                                            answer[key]=str(m)+\"_1_\"\n",
    "                    temp_s=\"\"     \n",
    "#                     print(answer)\n",
    "                    for key in answer.keys():\n",
    "                        temp_s+=\"|\"+key+\":\"+answer[key]\n",
    "                    answer.clear()\n",
    "                    flag=True\n",
    "                    intersection.clear()\n",
    "                    intersection.append(temp_s)   \n",
    "            if(flag):        \n",
    "                docs=intersection[0].split(\"|\")\n",
    "                for x in docs:\n",
    "                    if(x!=''):\n",
    "                        docid=x.split(\":\")[0].split(\"c\")[1]\n",
    "                        count=x.split(\":\")[1].split(\"_\")\n",
    "                        count=int(count[len(count)-2])\n",
    "                        if(docid in docs_point):\n",
    "                            docs_point[docid]+=count*100\n",
    "                        else:\n",
    "                             docs_point[docid]=count*100\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3ff64aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for address in query_dic:\n",
    "        if(type(address) is not list):\n",
    "            docs=address.split(\"|\")\n",
    "            for x in docs:\n",
    "                if(x!=''):\n",
    "                    docid=x.split(\":\")[0].split(\"c\")[1]\n",
    "                    count=x.split(\":\")[1].split(\"_\")\n",
    "                    count=int(count[len(count)-2])\n",
    "                    if(docid in docs_point):\n",
    "                        docs_point[docid]+=count\n",
    "                    else:\n",
    "                         docs_point[docid]=count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992d6267",
   "metadata": {},
   "source": [
    "### check ! for remove from answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a4e5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for address in forbidden_dic:\n",
    "    doc_id=address.split(\"|\")\n",
    "    for x in doc_id:\n",
    "        if(x!=''):\n",
    "            docid=x.split(\":\")[0].split(\"c\")[1]\n",
    "            if(docid in docs_point):\n",
    "                docs_point.pop(docid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725cece",
   "metadata": {},
   "source": [
    "### print answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78f96b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no answwr found for your query\n"
     ]
    }
   ],
   "source": [
    "# data_content=[]\n",
    "# data_url=[]\n",
    "# data_title=[]\n",
    "final_answer=[]\n",
    "if(len(docs_point)==0):\n",
    "    print(\"no answer found for your query\")  \n",
    "else:\n",
    "    if(len(docs_point)>=5):\n",
    "        for i in range(5):\n",
    "            maximum=0\n",
    "            max_id=\"\"\n",
    "            for docid in docs_point.keys():\n",
    "                if(docs_point[docid]>maximum):\n",
    "                    maximum=docs_point[docid]\n",
    "                    max_id=docid\n",
    "            final_answer.append(max_id)\n",
    "            docs_point.pop(max_id)\n",
    "    else:\n",
    "         for i in range(len(docs_point)):\n",
    "            maximum=0\n",
    "            max_id=\"\"\n",
    "            for docid in docs_point.keys():\n",
    "                if(docs_point[docid]>maximum):\n",
    "                    maximum=docs_point[docid]\n",
    "                    max_id=docid\n",
    "            final_answer.append(max_id)\n",
    "            docs_point.pop(max_id)\n",
    "    count=0    \n",
    "    for k in final_answer:\n",
    "        docid=int(k)\n",
    "        print(\"answer \"+str(count+1)+\": \")\n",
    "        print(\"title: \"+data_title[docid])\n",
    "        print(\"url: \"+data_url[docid])\n",
    "        print(docid)\n",
    "        print(data_content[docid])\n",
    "        count+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e4250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfda155",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
